{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ue5hxxkdAQJg"},"source":["<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## Vectorización\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"kCED1hh-Ioyf"},"outputs":[],"source":["import numpy as np\n","np.set_printoptions(threshold=np.inf, edgeitems=50,linewidth=200) # para mostrar mas elementos en print(np.array)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"PUbfVnzIIoMj"},"outputs":[],"source":["def cosine_similarity(a, b):\n","    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"DMOa4JPSCJ29"},"source":["### Datos"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"RIO7b8GjAC17"},"outputs":[],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"8WqdaTmO8P1r"},"source":["Documento 1 --> que dia es hoy \\\n","Documento 2 --> martes el dia de hoy es martes \\\n","Documento 3 --> martes muchas gracias"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"FVHxBRNzCMOS"},"source":["### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n","- Cada documento transformarlo en una lista de términos\n","- Armar un vector de términos no repetidos de todos los documentos"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["def get_unique_text(corpus : np.ndarray) -> np.ndarray:\n","    \"\"\"\n","    Gets unique words from a corpus\n","\n","    Args:\n","        corpus -> np.ndarray: array of corpus text.\n","\n","    Returns:\n","        rtype -> np.ndarray: array with unique words\n","    \"\"\"\n","    temp = []\n","    for phrase in corpus:\n","        temp.append(phrase.lower().split())\n","\n","    vector = np.hstack(temp)\n","    uniques = np.unique(vector) \n","    return vector , uniques"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['que' 'dia' 'es' 'hoy' 'martes' 'el' 'dia' 'de' 'hoy' 'es' 'martes' 'martes' 'muchas' 'gracias']\n","['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que']\n"]}],"source":["text, unique_text = get_unique_text(corpus)\n","print(text)\n","print(unique_text)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"RUhH983FI7It"},"source":["### 2- OneHot encoding\n","Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"Os0AAQo6I6Z1"},"outputs":[],"source":["def one_hot_encoding(text_list : np.ndarray, show_columns = False)-> np.ndarray:\n","    \"\"\"\n","    Performs one-hot encoding onto an array of texts.\n","\n","    Args:\n","        text_list : np.ndarray -> array of texts.\n","        show_columns : bool -> whether to show or not the columns of the one-hot encoding matrix\n","    \n","    Returns:\n","        np.ndarray -> one-hot encoding matrix\n","\n","    \"\"\"\n","    unique, inverse = np.unique(text_list, return_inverse=True)\n","    onehot = np.eye(unique.shape[0])[inverse]\n","    if show_columns:\n","        print(unique)\n","    return onehot"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que']\n"]},{"data":{"text/plain":["array([[0., 0., 0., 0., 0., 0., 0., 0., 1.],\n","       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n","       [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n","       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","       [1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 1., 0., 0., 0.],\n","       [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n","       [0., 0., 0., 0., 1., 0., 0., 0., 0.]])"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["one_hot_encoding(text, True)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"IIyWGmCpJVQL"},"source":["### 3- Vectores de frecuencia\n","Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["def get_frequency_matrix(corpus:np.ndarray, unique_text:np.ndarray, show_columns = False) -> np.ndarray:\n","    \"\"\"\n","    Creates a matrix, representing the frequency of every word within a corpus.\n","\n","    Args:\n","        corpus : np.ndarray -> corpus of text.\n","        unique_text : np.ndarray -> list of unique words.\n","        show_columns : bool -> whether to print or not the columns of the matrix.\n","    Returns:\n","        np.ndarray -> frequency matrix.\n","    \"\"\"\n","    frequency_matrix = np.zeros((corpus.size,unique_text.size))\n","    for i,word  in enumerate(corpus):\n","        for  j,unique_word in enumerate(unique_text):\n","            \n","            if unique_word in word.lower().split():\n","                \n","                frequency_matrix[i,j] = word.lower().split().count(unique_word)\n","    if show_columns:\n","        print(\"columns:\",unique_text)\n","    return frequency_matrix"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'], dtype='<U30')"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["corpus"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/plain":["array(['de', 'dia', 'el', 'es', 'gracias', 'hoy', 'martes', 'muchas', 'que'], dtype='<U7')"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["unique_text"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["columns: ['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que']\n"]},{"data":{"text/plain":["array([[0., 1., 0., 1., 0., 1., 0., 0., 1.],\n","       [1., 1., 1., 1., 0., 1., 2., 0., 0.],\n","       [0., 0., 0., 0., 1., 0., 1., 1., 0.]])"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["get_frequency_matrix(corpus, unique_text, True)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"z_Ot8HvWJcBu"},"source":["### 4- TF-IDF\n","Data una lista de textos, devolver una matriz con la representacion TFIDF"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"waG_oWtpJjRw"},"outputs":[],"source":["def get_tf_idf(corpus : np.ndarray, show_columns = False)-> np.ndarray:\n","    \"\"\"\n","    Applies TF-IDF vector representation onto a corpus of text.\n","    \n","    Args:\n","        corpus : np.ndarray -> corpus of text.\n","        show_columns : bool -> whether to show or not the matrix columns\n","    \"\"\"\n","    text, unique_text = get_unique_text(corpus)\n","    n = np.sum(one_hot_encoding(text),axis =0)\n","\n","    idf = np.log10(corpus.size/n)\n","    tf = get_frequency_matrix(corpus,unique_text)\n","    if show_columns:\n","        print(unique_text)\n","    return tf*idf\n","    "]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que']\n"]},{"data":{"text/plain":["array([[0.        , 0.17609126, 0.        , 0.17609126, 0.        , 0.17609126, 0.        , 0.        , 0.47712125],\n","       [0.47712125, 0.17609126, 0.47712125, 0.17609126, 0.        , 0.17609126, 0.        , 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.47712125, 0.        , 0.        , 0.47712125, 0.        ]])"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["get_tf_idf(corpus, True)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xMcsfndWJjm_"},"source":["### 5 - Comparación de documentos\n","Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"CZdiop6IJpZN"},"outputs":[],"source":["def order_by_cosine(corpus: np.ndarray,index : int, show_similarities = False):\n","    \"\"\"\n","    Applies the cosine similarity between a indexed text(target) and all of the corpus,\n","    returns the corpus ordered by similarities.\n","\n","    Args:\n","        corpus : np.ndarray -> corpus of documents.\n","        index : int -> target vector\n","        show_similarities : bool -> whether to show or not the similarity vector.\n","    \n","    \"\"\"\n","    similarity = []\n","    tf_idf = get_tf_idf(corpus)\n","    try:\n","        target = tf_idf[index]\n","        for i in tf_idf:\n","\n","            similarity.append(cosine_similarity(i,target))\n","        similarity = np.array(similarity)\n","        if show_similarities:\n","            print(similarity[similarity.argsort()[::-1]])\n","        return(corpus[similarity.argsort()[::-1]])\n","    except Exception as err:\n","        print(err)\n"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[1.         0.22184708 0.        ]\n"]},{"data":{"text/plain":["array(['martes el dia de hoy es martes', 'que dia es hoy', 'martes muchas gracias'], dtype='<U30')"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["order_by_cosine(corpus, 1, True)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO5fRYTpympAwJSVbric6dW","collapsed_sections":[],"name":"1a - word2vec.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":0}
